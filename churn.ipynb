{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cm3K4WhHIIE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "# Load the dataset\n",
        "data = pd.read_excel('customer_churn_large_dataset.xlsx')\n",
        "\n",
        "# Handle missing data (e.g., remove or impute missing values)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Handle outliers (you can use techniques like IQR or Z-score)\n",
        "Q1 = data['Monthly_Bill'].quantile(0.25)\n",
        "Q3 = data['Monthly_Bill'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "data = data[(data['Monthly_Bill'] >= Q1 - 1.5 * IQR) & (data['Monthly_Bill'] <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "# Encode categorical variables (e.g., one-hot encoding for 'Gender' and 'Location')\n",
        "data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X = data.drop('Churn', axis=1)\n",
        "y = data['Churn']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Drop the 'CustomerID' and 'Name' column as it's not a relevant feature for prediction\n",
        "X_train = X_train.drop('CustomerID', axis=1)\n",
        "X_test = X_test.drop('CustomerID', axis=1)\n",
        "X_train = X_train.drop('Name', axis=1)\n",
        "X_test = X_test.drop('Name', axis=1)\n",
        "\n",
        "# Step 2: Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Model Building (Random Forest)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 4: Model Optimization (Random Forest) - Example\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train_scaled, y_train)\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Step 5: Model Building (Logistic Regression)\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Step 6: Model Optimization (Logistic Regression) - Example\n",
        "param_grid_logistic = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'lbfgs', 'saga']\n",
        "}\n",
        "\n",
        "grid_search_logistic = GridSearchCV(LogisticRegression(), param_grid_logistic, cv=5, scoring='accuracy')\n",
        "grid_search_logistic.fit(X_train_scaled, y_train)\n",
        "best_logistic_model = grid_search_logistic.best_estimator_\n",
        "\n",
        "# Step 7: Model Evaluation\n",
        "def evaluate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred)\n",
        "    recall = recall_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate Random Forest Model\n",
        "rf_accuracy, rf_precision, rf_recall, rf_f1 = evaluate_model(best_rf_model, X_test_scaled, y_test)\n",
        "\n",
        "# Evaluate Logistic Regression Model\n",
        "logistic_accuracy, logistic_precision, logistic_recall, logistic_f1 = evaluate_model(best_logistic_model, X_test_scaled, y_test)\n",
        "\n",
        "# Print evaluation metrics for both models\n",
        "print(\"Random Forest Model Metrics:\")\n",
        "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
        "print(f\"Precision: {rf_precision:.2f}\")\n",
        "print(f\"Recall: {rf_recall:.2f}\")\n",
        "print(f\"F1-Score: {rf_f1:.2f}\")\n",
        "\n",
        "print(\"\\nLogistic Regression Model Metrics:\")\n",
        "print(f\"Accuracy: {logistic_accuracy:.2f}\")\n",
        "print(f\"Precision: {logistic_precision:.2f}\")\n",
        "print(f\"Recall: {logistic_recall:.2f}\")\n",
        "print(f\"F1-Score: {logistic_f1:.2f}\")\n",
        "\n",
        "# Step 8: Save the Best Model\n",
        "# Save the best model to a file (you can choose either the Random Forest or Logistic Regression model)\n",
        "joblib.dump(best_rf_model, 'churn_model.pkl')\n",
        "# joblib.dump(best_logistic_model, 'churn_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model in a production-like environment (simulated deployment)\n",
        "loaded_model = joblib.load('churn_model.pkl')\n",
        "\n",
        "\n",
        "# Make predictions on new data\n",
        "new_data = pd.DataFrame({\n",
        "    'Age': [30],\n",
        "    'Subscription_Length_Months': [12],\n",
        "    'Monthly_Bill': [50],\n",
        "    'Total_Usage_GB': [100],\n",
        "    'Gender_Male': [0],\n",
        "    'Location_Houston': [0],  # Include all one-hot encoded location columns with appropriate values\n",
        "    'Location_Los Angeles': [0],\n",
        "    'Location_Miami': [0],\n",
        "    'Location_New York': [0],  # Set the relevant location to 1 if needed\n",
        "\n",
        "})\n",
        "prediction = loaded_model.predict(new_data)\n",
        "\n",
        "# Print the churn prediction\n",
        "if prediction[0] == 1:\n",
        "    print(\"This customer is likely to churn.\")\n",
        "else:\n",
        "    print(\"This customer is likely to stay.\")\n",
        "\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DglccTdqIqtf",
        "outputId": "939acf79-2faa-4d62-9c40-afe99d47f2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This customer is likely to stay.\n",
            "Accuracy: 0.50\n",
            "Precision: 0.49\n",
            "Recall: 0.47\n",
            "F1-Score: 0.48\n"
          ]
        }
      ]
    }
  ]
}